{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/oss-mldl/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import h5py\n",
    "from Augmentation import RandomCrop, CenterCrop, RandomFlip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_MRIs(image):\n",
    "    mean = np.mean(image)\n",
    "    std = np.std(image)\n",
    "    image -= mean\n",
    "    #image -= 95.09\n",
    "    image /= std\n",
    "    #image /= 86.38\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OAI_Dataloader(Dataset):\n",
    "    \"\"\"OAI dataset. Sequences of images, each sequence labeled by 0 or 1 (TKR or not)\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, csv_root_dir, csv_file, dim=(384,384,32), \n",
    "                 normalize = True, randomCrop = True, \n",
    "                 randomFlip = True, flipProbability = -1, cropDim = (384,384,32)):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.data = pd.read_csv(csv_root_dir + csv_file)[0:10]\n",
    "        self.folders = ['00m']\n",
    "        self.dim = dim\n",
    "        self.normalize = normalize\n",
    "        self.randomCrop = randomCrop\n",
    "        self.randomFlip = randomFlip\n",
    "        self.flipProbability = flipProbability\n",
    "        self.cropDim = cropDim\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\" returns img, label with : img = [batch_size, 1, X, Y, Z] \n",
    "                                      label in {0,1}\n",
    "        \"\"\"\n",
    "        file = self.data['FileName'].iloc[idx]\n",
    "        \n",
    "        img_seq = []\n",
    "        k = 0\n",
    "        for folder in self.folders:\n",
    "            #pre_image = h5py.File(self.root_dir + folder + '/' + file, \"r\")['data/'].value.astype('float64')\n",
    "            pre_image = h5py.File(self.root_dir + file, \"r\")['data/'].value.astype('float64')\n",
    "            if self.normalize:\n",
    "                pre_image = normalize_MRIs(pre_image)\n",
    "            # Augmentation\n",
    "            if self.randomFlip:\n",
    "                pre_image = RandomFlip(image=pre_image,p=0.5).horizontal_flip(p=self.flipProbability)\n",
    "            if self.randomCrop:\n",
    "                pre_image = RandomCrop(pre_image).crop_along_hieght_width_depth(self.cropDim)\n",
    "            else:\n",
    "                pre_image = CenterCrop(image=pre_image).crop(size = self.cropDim)\n",
    "                \n",
    "            img_seq.append(pre_image)\n",
    "            k += 1\n",
    "\n",
    "        img_seq = torch.tensor(torch.from_numpy(np.array(img_seq)), dtype=torch.float)\n",
    "\n",
    "        label = int(self.data['NumberOfDaysFromScanToTKR'].iloc[idx] != 0)\n",
    "         \n",
    "        return (img_seq, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test1\n",
    "# root_dir = '/gpfs/data/denizlab/Datasets/OAI/SAG_3D_DESS/'\n",
    "# csv_file = 'HDF5_00_SAG_3D_DESScohort_2_prime.csv'\n",
    "\n",
    "#test2\n",
    "csv_root_dir = '/home/yangj14/oai/Tianyu/data/'\n",
    "root_dir = '/gpfs/data/denizlab/Datasets/OAI/SAG_IW_TSE/'\n",
    "train_csv_file = 'Fold1_train.csv'\n",
    "val_csv_file = 'Fold1_val.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'dim': (384,384,32),\n",
    "          'normalize' : False,\n",
    "          'randomCrop' : False,\n",
    "          'randomFlip' : False,\n",
    "          'flipProbability' : -1,\n",
    "          'cropDim' : (384,384,32)}\n",
    "\n",
    "train_dataset = OAI_Dataloader(root_dir, csv_root_dir, train_csv_file, **train_params)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "val_dataset = OAI_Dataloader(root_dir, csv_root_dir, val_csv_file, **train_params)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 384, 384, 32])\n",
      "tensor([ 0,  0])\n",
      "torch.Size([2, 1, 384, 384, 32])\n",
      "tensor([ 0,  0])\n",
      "torch.Size([2, 1, 384, 384, 32])\n",
      "tensor([ 0,  1])\n",
      "torch.Size([2, 1, 384, 384, 32])\n",
      "tensor([ 0,  1])\n",
      "torch.Size([2, 1, 384, 384, 32])\n",
      "tensor([ 1,  1])\n"
     ]
    }
   ],
   "source": [
    "for im, l in train_dataloader:\n",
    "    print(im.shape)\n",
    "    print(l)\n",
    "    #print((torch.tensor(im, dtype=torch.double)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''VGG11/13/16/19 in Pytorch'''\n",
    "# Only tried model with one data point. Need to load more data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(4608, 2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        #print(out.shape)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 1\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))]\n",
    "            elif x == 64:\n",
    "                layers += [nn.Conv3d(in_channels, x, kernel_size=(3, 3, 3), stride = (2, 2,1), padding=1),\n",
    "                           nn.BatchNorm3d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "            else:\n",
    "                layers += [nn.Conv3d(in_channels, x, kernel_size=(3, 3, 3), stride = (1, 1,1), padding=1),\n",
    "                           nn.BatchNorm3d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool3d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "# net = VGG('VGG11')\n",
    "# x = torch.randn(2,3,32,32)\n",
    "# print(net(Variable(x)).size())\n",
    "\n",
    "\n",
    "# net = VGG('VGG16')\n",
    "# for im, l in train_dataloader:\n",
    "#     print(net(im).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cuda = False\n",
    "log_interval = 1\n",
    "\n",
    "cuda = not no_cuda and torch.cuda.is_available()\n",
    "# cuda = False\n",
    "\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "# kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.72023869212717\n",
      "[60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0]\n"
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "def test_model(loader, model):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for im, labels in loader:\n",
    "        im, labels = im.to(device), labels.to(device)\n",
    "        outputs = F.softmax(model(im), dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    return (100 * correct / total)\n",
    "\n",
    "import timeit\n",
    "start = timeit.default_timer()\n",
    "\n",
    "model = VGG('VGG16').to(device)\n",
    "\n",
    "learning_rate = 0.00005\n",
    "num_epochs = 20 # number epoch to train\n",
    "\n",
    "# Criterion and Optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_dataloader)\n",
    "\n",
    "val_accuracy_100_vgg = []\n",
    "val_accuracy_epoch_vgg = []\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (im, labels) in enumerate(train_dataloader):\n",
    "        im, labels = im.to(device), labels.to(device)\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(im)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # validate every 100 iterations\n",
    "        if i > 0 and i % 100 == 0:\n",
    "            # validate\n",
    "            val_acc = test_model(val_dataloader, model)\n",
    "            print('Epoch: [{}/{}], Step: [{}/{}], Validation Acc: {}'.format(\n",
    "                       epoch+1, num_epochs, i+1, len(train_loader), val_acc))\n",
    "            val_accuracy_100_vgg.append(val_acc)\n",
    "    val_acc = test_model(val_dataloader, model)\n",
    "    val_accuracy_epoch_vgg.append(val_acc)\n",
    "    \n",
    "    \n",
    "stop = timeit.default_timer()\n",
    "print(stop - start)\n",
    "\n",
    "print(val_accuracy_epoch_vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
